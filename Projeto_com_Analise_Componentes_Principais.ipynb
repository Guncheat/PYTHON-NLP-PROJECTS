{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GX_XRt98ixI",
        "outputId": "dbf25b84-257a-4b34-bb7d-01d193cd48a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K\n",
            "added 22 packages in 3s\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K\u001b[31mERROR: Could not find a version that satisfies the requirement itertools (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for itertools\u001b[0m\u001b[31m\n",
            "\u001b[0mPacotes Instalados\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit -q\n",
        "!npm install localtunnel -q\n",
        "!pip install sklearn.preprocessing -q\n",
        "!pip install scikit-learn -q\n",
        "!pip install itertools -q\n",
        "!pip install xgboost -q\n",
        "print(\"Pacotes Instalados\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dO_8TduANmQ7",
        "outputId": "ad99b7c8-2da0-458f-e1d1-56ffb78887d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting Soccer_Players_Statistics_PCA.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile Soccer_Players_Statistics_PCA.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
        "from xgboost import XGBClassifier\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import combinations\n",
        "\n",
        "# Título da aplicação\n",
        "st.set_page_config(page_title=\"Análise de Componentes Principais - Jogadores de Futebol\", layout=\"wide\")\n",
        "st.title('Análise de Componentes Principais - Jogadores de Futebol')\n",
        "\n",
        "try:\n",
        "  with st.sidebar:\n",
        "    uploaded_file = st.file_uploader(\"Faça o upload do arquivo CSV\", type=[\"csv\"])\n",
        "    n_components = st.slider('Número de componentes:', 1, 5, 2)\n",
        "\n",
        "  if uploaded_file is not None:\n",
        "    df = pd.read_csv(uploaded_file)\n",
        "    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "    selected_cols = st.sidebar.multiselect('Selecione as colunas numéricas para a análise:', numeric_cols, default=numeric_cols[:5])\n",
        "    process_button = st.sidebar.button(\"Processar\")\n",
        "\n",
        "    if process_button:\n",
        "      if not selected_cols:\n",
        "        st.warning('Selecione ao menos uma coluna para prosseguir.')\n",
        "      else:\n",
        "        st.markdown(\"---\")\n",
        "        df_selected = df[selected_cols]\n",
        "        with st.expander('O que é análise de componentes principais(PCA)?'):\n",
        "          st.write(\"\"\"\n",
        "          A análise de componentes principais (PCA) reduz o número de dimensões em grandes conjuntos de dados para os componentes principais que retêm a maior parte das informações originais. Ela faz isso transformando variáveis potencialmente correlacionadas em um conjunto menor de variáveis, chamadas componentes principais. \\n\"\"\")\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        with st.expander('Quando Utilizar a Técnica de PCA (Análise de Componentes Principais)?'):\n",
        "          st.write(\"\"\"A Análise de Componentes Principais (PCA) é uma técnica de redução de dimensionalidade amplamente utilizada em machine learning e estatística. Ela é especialmente útil nas seguintes situações:\n",
        "          * Redução de Dimensionalidade\n",
        "          * Visualização de Dados\n",
        "          * Remoção de Correlação entre Variáveis\n",
        "          * Pré-processamento para Outros Algoritmos\n",
        "          * Tratamento de Multicolinearidade\"\"\")\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        with st.expander('Quando não utilizar o PCA?'):\n",
        "          st.write(\"\"\"* Se a interpretabilidade das variáveis originais é essencial.\n",
        "          * Se os dados já possuem baixa dimensionalidade.\n",
        "          * Se as variáveis possuem escalas muito diferentes (nesse caso, padronize os dados antes).\n",
        "          O PCA é uma ferramenta poderosa, mas seu uso deve ser justificado pelo problema e pela natureza dos dados.\"\"\")\n",
        "        st.markdown(\"---\")\n",
        "        with st.expander('Visualização dos dados selecionados'):\n",
        "          st.write(df_selected.head())\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # Lidar com valores ausentes (NaN) usando a mediana\n",
        "        imputer = SimpleImputer(strategy='median')\n",
        "        df_imputed = pd.DataFrame(imputer.fit_transform(df_selected), columns=df_selected.columns)\n",
        "\n",
        "        # Padronizar os dados\n",
        "        x = StandardScaler().fit_transform(df_imputed)\n",
        "\n",
        "        # PCA\n",
        "        pca = PCA(n_components=n_components)\n",
        "        principalComponents = pca.fit_transform(x)\n",
        "        principalDf = pd.DataFrame(data = principalComponents, columns = [f'Componente Principal {i+1}' for i in range(n_components)])\n",
        "\n",
        "        with st.expander('Gráfico de Correlação'):\n",
        "          correlation_matrix = df_selected.corr()\n",
        "          fig_corr = px.imshow(correlation_matrix, text_auto=True, title='Matriz de Correlação')\n",
        "          st.plotly_chart(fig_corr)\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # Gráfico de variância explicada\n",
        "        with st.expander('Gráfico de variância explicada'):\n",
        "          explained_variance_ratio = pca.explained_variance_ratio_\n",
        "          cumulative_variance = np.cumsum(explained_variance_ratio)\n",
        "          fig_variance = px.bar(x=[f'Componente {i+1}' for i in range(n_components)], y=explained_variance_ratio, title='Variância Explicada por Componente', labels={'x':'Componente',\"y\":'Variância Explicada'})\n",
        "          st.plotly_chart(fig_variance)\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # Tabela de variância acumulada\n",
        "        with st.expander('Tabela de variância acumulada'):\n",
        "          df_variance = pd.DataFrame({'Componente': [f'Componente {i+1}' for i in range(n_components)], 'Variância': explained_variance_ratio})\n",
        "          df_variance['Variância Acumulada'] = cumulative_variance\n",
        "          st.dataframe(df_variance)\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        #Tabela com as contribuições de cada variável por componente\n",
        "        with st.expander(\"Tabela das contribuições de cada componente\"):\n",
        "          loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
        "          loadings_df = pd.DataFrame(loadings, columns=[f\"PC{i+1}\" for i in range(n_components)], index=selected_cols)\n",
        "          st.dataframe(loadings_df)\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # Mostrar as primeiras linhas do DataFrame com os componentes\n",
        "        with st.expander('Primeiras linhas do DataFrame com os componentes'):\n",
        "          st.write(principalDf.head())\n",
        "        st.markdown(\"---\")\n",
        "        with st.expander('Comparação dos Modelos'):\n",
        "          if 'Rating' in df.columns:\n",
        "            # Prepare data for classification\n",
        "            df_pca_rating = pd.concat([principalDf, df['Rating']], axis=1)\n",
        "            X = df_pca_rating.drop('Rating', axis=1)\n",
        "            y = df_pca_rating['Rating']\n",
        "\n",
        "            # Convert Rating to categorical (assuming it needs to be for logistic regression)\n",
        "            y = pd.cut(y, bins=3, labels=[0,1,2], include_lowest=True, duplicates='drop')\n",
        "            # Split data\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "            # Logistic Regression\n",
        "            logreg = LogisticRegression()\n",
        "            logreg.fit(X_train, y_train)\n",
        "            y_pred_logreg = logreg.predict(X_test)\n",
        "\n",
        "            # XGBoost\n",
        "            xgb = XGBClassifier()\n",
        "            xgb.fit(X_train, y_train)\n",
        "            y_pred_xgb = xgb.predict(X_test)\n",
        "\n",
        "            # Evaluate models\n",
        "            st.subheader(\"Avaliação dos modelos\")\n",
        "            models = {\n",
        "                \"Regressão Logística\": y_pred_logreg,\n",
        "                \"XGBoost\": y_pred_xgb\n",
        "            }\n",
        "            for model_name, y_pred in models.items():\n",
        "              accuracy = accuracy_score(y_test, y_pred)\n",
        "              recall = recall_score(y_test, y_pred,average='macro')\n",
        "              f1 = f1_score(y_test, y_pred,average='macro')\n",
        "              st.write(f\"{model_name}:\")\n",
        "              st.write(f\"- Precisão: {accuracy:.4f}\")\n",
        "              st.write(f\"- Recall: {recall:.4f}\")\n",
        "              st.write(f\"- F1-score: {f1:.4f}\")\n",
        "              st.markdown(\"---\")\n",
        "          else:\n",
        "            st.warning(\"Coluna 'Rating' não encontrada no dataset. Não foi possível realizar a análise.\")\n",
        "            st.markdown(\"---\")\n",
        "    else:\n",
        "      st.write(\"Aguardando o clique em 'Processar'...\")\n",
        "  else:\n",
        "    st.warning(\"Por favor, faça o upload de um arquivo CSV.\")\n",
        "except:\n",
        "      st.warning(\"Por favor, faça o upload de um arquivo CSV.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McsL-PAD8hjQ",
        "outputId": "94572004-1fef-4f70-c79a-65d04ca5a017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.150.167.133\n"
          ]
        }
      ],
      "source": [
        "!curl ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmGb_vrA9u09",
        "outputId": "a33c44c6-9b2f-48d5-b67f-467b3930f6b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.150.167.133:8501\u001b[0m\n",
            "\u001b[0m\n",
            "your url is: https://hungry-lies-call.loca.lt\n"
          ]
        }
      ],
      "source": [
        "!streamlit run Soccer_Players_Statistics_PCA.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
